# -*- coding: utf-8 -*-
"""chatbot.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1feCkdIYr8e1V5KIzxxooJr5o2bRK4R4p
"""

import nltk
import random
import numpy as np
import json
import pickle
from nltk.stem import WordNetLemmatizer
from tensorflow.keras.models import load_model
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
lemmatizer=WordNetLemmatizer()

with open('C:\Health Care ChatBot\Health-Care-Chatbot\intents.json') as json_file:
    intents = json.load(json_file)

model=load_model('chatbotmodel.h5')
words=pickle.load(open('words.pkl','rb'))
intents = json.loads(open("C:\Health Care ChatBot\Health-Care-Chatbot\intents.json").read())
classes=pickle.load(open('classes.pkl','rb'))


def clean_up_sentence(sentence):
  sentence_words=nltk.word_tokenize(sentence)
  sentence_words=[lemmatizer.lemmatize(word) for word in sentence_words]
  return sentence_words

def bow(sentence, words, show_details=True):
    sentence_words = clean_up_sentence(sentence)
    bag = [0] * len(words)
    for s in sentence_words:
        for i, w in enumerate(words):
            if w == s:
                bag[i] = 1
                if show_details:
                    print(f"found in bag: {w}")
    return np.array(bag)

def predict_class(sentence):
    p = bow(sentence, words, show_details=False)
    res = model.predict(np.array([p]))[0]
    ERROR_THRESHOLD = 0.25
    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]
    results.sort(key=lambda x: x[1], reverse=True)
    return_list = []
    for r in results:
        return_list.append({"intent": classes[r[0]], "probability": str(r[1])})
    return return_list


# Get response
def get_response(intents_list, intents_json):
    if len(intents_list) == 0:
        return "I'm sorry, I didn't understand that."
    tag = intents_list[0]["intent"]
    list_of_intents = intents_json["intents"]
    for i in list_of_intents:
        if i["tag"] == tag:
            return random.choice(i["responses"])
    return "I'm sorry, I didn't understand that."

# Main function GUI will use
patterns = []
tags = []
for intent in intents["intents"]:
    for pattern in intent["patterns"]:
        patterns.append(pattern.lower())
        tags.append(intent["tag"])

# Train vectorizer on patterns
vectorizer = CountVectorizer().fit(patterns)

# -------------------------
# Chatbot Response Function
# -------------------------
def chatbot_response(user_input):
    # Convert to vectors
    X_patterns = vectorizer.transform(patterns)
    X_user = vectorizer.transform([user_input.lower()])

    # Find best match
    similarities = cosine_similarity(X_user, X_patterns)
    best_match_idx = similarities.argmax()

    tag = tags[best_match_idx]

    # Pick random response from intents.json
    for intent in intents["intents"]:
        if intent["tag"] == tag:
            return random.choice(intent["responses"])

    return "I'm sorry, I didn't understand that."
# ✅ Don’t run anything if imported
if __name__ == "__main__":
    print("GO! BOT IS RUNNING")
    while True:
        msg = input("Nikk: ")
        print("MedBot:", chatbot_response(msg))